{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 02 — Feature Engineering\n",
                "\n",
                "Transform raw listings and reviews into modelling-ready features:\n",
                "1. **Sentiment Analysis** — VADER polarity scores on 1.3M+ reviews\n",
                "2. **Amenity Extraction** — 30+ binary features from free-text amenities\n",
                "3. **Host Features** — verification methods, response time encoding\n",
                "4. **Location Features** — Haversine distance to city centre\n",
                "5. **Date Features** — hosting duration, time to first review\n",
                "6. **Categorical Encoding** — property type, room type, neighbourhood one-hot encoding\n",
                "7. **Final Feature Set** — 140 explanatory variables"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "sys.path.insert(0, '..')\n",
                "\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "from src.data_loader import load_listings, load_reviews\n",
                "from src.data_cleaning import clean_listings\n",
                "from src.feature_engineering import (\n",
                "    compute_vader_sentiment,\n",
                "    aggregate_sentiment_by_listing,\n",
                "    merge_sentiment,\n",
                "    create_amenity_dummies,\n",
                "    encode_host_verifications,\n",
                "    encode_host_response_time,\n",
                "    group_rare_property_types,\n",
                "    one_hot_encode_categoricals,\n",
                "    compute_date_features,\n",
                "    compute_city_center_distance,\n",
                "    log_transform_price,\n",
                "    drop_text_columns,\n",
                ")\n",
                "from src.data_cleaning import clean_percentage_columns, filter_valid_listings\n",
                "from src.config import AMENITY_KEYWORDS, URL_AND_REDUNDANT_COLUMNS\n",
                "from src.visualization import set_style\n",
                "\n",
                "set_style()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load and Clean Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "listings_raw = load_listings()  # Uses DEFAULT_CITY from config\n",
                "reviews_raw = load_reviews()  # Uses DEFAULT_CITY from config\n",
                "\n",
                "listings = clean_listings(listings_raw)\n",
                "print(f'Cleaned listings: {listings.shape[0]:,} rows × {listings.shape[1]} columns')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Sentiment Analysis (VADER)\n",
                "\n",
                "Apply VADER sentiment analysis to each review comment, then compute the\n",
                "mean polarity score per listing."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# This cell may take several minutes for 1.3M+ reviews\n",
                "reviews_scored = compute_vader_sentiment(reviews_raw)\n",
                "print(f'Reviews scored: {len(reviews_scored):,}')\n",
                "reviews_scored[['comments', 'neg', 'neu', 'pos', 'compound']].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sentiment_agg = aggregate_sentiment_by_listing(reviews_scored)\n",
                "listings = merge_sentiment(listings, sentiment_agg)\n",
                "print(f'Listings with sentiment: {listings.shape}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Amenity Extraction\n",
                "\n",
                "Create binary dummy variables for 30+ amenity categories using keyword matching."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(f'Amenity categories: {len(AMENITY_KEYWORDS)}')\n",
                "for name, keywords in list(AMENITY_KEYWORDS.items())[:5]:\n",
                "    print(f'  {name}: {keywords[:3]}...')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "listings = create_amenity_dummies(listings)\n",
                "amenity_cols = list(AMENITY_KEYWORDS.keys())\n",
                "print('Amenity feature coverage:')\n",
                "print(listings[amenity_cols].sum().sort_values(ascending=False))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Host Feature Encoding"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "listings = encode_host_verifications(listings)\n",
                "listings = encode_host_response_time(listings)\n",
                "print('Host features added:', ['email_verified', 'phone_verified',\n",
                "      'host_response_within_hour', 'host_response_few_hours',\n",
                "      'host_response_within_day', 'host_response_few_days'])"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Property Type Grouping & Categorical Encoding"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "listings = group_rare_property_types(listings)\n",
                "print('Property types after grouping:')\n",
                "print(listings['property_type'].value_counts())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "listings = one_hot_encode_categoricals(listings)\n",
                "print(f'Columns after one-hot encoding: {listings.shape[1]}')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Date Features & Distance"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "listings = log_transform_price(listings)\n",
                "listings = compute_date_features(listings)\n",
                "listings = compute_city_center_distance(listings)  # Uses DEFAULT_CITY from config\n",
                "\n",
                "print('New features: hosting_duration_days, joining_to_first_review_duration, distance_to_city_center')\n",
                "listings[['hosting_duration_days', 'joining_to_first_review_duration', 'distance_to_city_center']].describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7. Final Cleanup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "listings = drop_text_columns(listings)\n",
                "listings = clean_percentage_columns(listings)\n",
                "\n",
                "print(f'\\nFinal feature set: {listings.shape[1]} columns × {listings.shape[0]:,} rows')\n",
                "print(f'\\nColumn names:')\n",
                "print(listings.columns.tolist())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "listings.describe()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.13.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
